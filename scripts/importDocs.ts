import * as fs from 'fs'
import * as path from 'path'
import { createClient } from '@sanity/client'
import { fileURLToPath } from 'url'

// --- Configuration ---
const PROJECT_ID = process.env.SANITY_STUDIO_PROJECT_ID || 'your-project-id'
const DATASET = process.env.SANITY_STUDIO_DATASET || 'production'
const API_TOKEN = process.env.SANITY_API_TOKEN // Needs write access
const DOCS_DIR = path.resolve(process.cwd(), 'docs-source') // Place your markdown files here for import

// ç¯å¢ƒå˜é‡æ£€æŸ¥
if (!API_TOKEN || API_TOKEN === 'your-write-token-here') {
    console.error('âŒ SANITY_API_TOKEN ç¯å¢ƒå˜é‡æœªè®¾ç½®æˆ–æ— æ•ˆ')
    console.log('\nè¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è·å– API Tokenï¼š')
    console.log('1. è®¿é—®ï¼šhttps://sanity.io/manage')
    console.log('2. é€‰æ‹©ä½ çš„é¡¹ç›®')
    console.log('3. è¿›å…¥ API -> Tokens')
    console.log('4. ç‚¹å‡» "Add API token"ï¼Œæƒé™é€‰æ‹© Editor æˆ– Administrator')
    console.log('5. å°†ç”Ÿæˆçš„ token è®¾ç½®ä¸ºç¯å¢ƒå˜é‡ SANITY_API_TOKEN\n')
    process.exit(1)
}

if (!PROJECT_ID || PROJECT_ID === 'your-project-id') {
    console.error('âŒ SANITY_STUDIO_PROJECT_ID ç¯å¢ƒå˜é‡æœªè®¾ç½®')
    process.exit(1)
}

// --- Types ---
interface DocCategory {
    _id: string
    _type: 'docCategory'
    title: string
    slug: { _type: 'slug'; current: string }
    order: number
    parentCategory?: { _type: 'reference'; _ref: string }
}

interface DocPage {
    _id: string
    _type: 'docPage'
    title: string
    slug: { _type: 'slug'; current: string }
    content: string
    category: { _type: 'reference'; _ref: string }
    order: number
}

// --- Helpers ---

// Simple frontmatter parser to avoid dependencies
function parseFrontmatter(content: string): { data: any; content: string } {
    const match = content.match(/^---[ \t]*\r?\n([\s\S]*?)\r?\n---[ \t]*(?:\r?\n)+([\s\S]*)$/)
    if (!match) return { data: {}, content }

    const frontmatterRaw = match[1]
    const body = match[2]
    const data: any = {}

    frontmatterRaw.split('\n').forEach((line) => {
        const [key, ...valueParts] = line.split(':')
        if (key && valueParts.length > 0) {
            let value = valueParts.join(':').trim()
            // Remove quotes if present
            if (value.startsWith('"') && value.endsWith('"')) {
                value = value.slice(1, -1)
            } else if (value.startsWith("'") && value.endsWith("'")) {
                value = value.slice(1, -1)
            }
            // Handle arrays (simple comma separated)
            if (value.startsWith('[') && value.endsWith(']')) {
                data[key.trim()] = value.slice(1, -1).split(',').map(s => s.trim())
            } else {
                data[key.trim()] = value
            }
        }
    })

    return { data, content: body }
}

function generateId(type: string, slug: string) {
    return `${type}-${slug}`.replace(/[^a-zA-Z0-9-_]/g, '-')
}

// --- Main Logic ---

async function main() {
    console.log(`ğŸ“š å¼€å§‹æ‰«ææ–‡æ¡£ç›®å½•: ${DOCS_DIR}`)

    if (!fs.existsSync(DOCS_DIR)) {
        console.error(`âŒ ç›®å½•ä¸å­˜åœ¨: ${DOCS_DIR}`)
        console.log('è¯·åˆ›å»º docs-source/ ç›®å½•å¹¶æ·»åŠ ä½ çš„ Markdown æ–‡æ¡£æ–‡ä»¶')
        console.log('å‚è€ƒç›®å½•ç»“æ„ï¼šdocs-source/README.md\n')
        return
    }

    const categories: DocCategory[] = []
    const pages: DocPage[] = []

    function processDirectory(dirPath: string, parentId?: string) {
        const items = fs.readdirSync(dirPath)

        // Filter and sort items
        const sortedItems = items.sort((a, b) => a.localeCompare(b, undefined, { numeric: true }))

        sortedItems.forEach((item, index) => {
            const fullPath = path.join(dirPath, item)
            const stats = fs.statSync(fullPath)

            if (stats.isDirectory()) {
                // It's a category
                const metaPath = path.join(fullPath, '_meta.json')
                let meta: any = { title: item, slug: item }

                if (fs.existsSync(metaPath)) {
                    try {
                        meta = JSON.parse(fs.readFileSync(metaPath, 'utf-8'))
                    } catch (e) {
                        console.warn(`âš ï¸  è§£æ _meta.json å¤±è´¥: ${fullPath}`)
                    }
                }

                const slug = meta.slug || item
                const categoryId = generateId('cat', slug)

                categories.push({
                    _id: categoryId,
                    _type: 'docCategory',
                    title: meta.title || item,
                    slug: { _type: 'slug', current: slug },
                    order: meta.order !== undefined ? meta.order : index,
                    parentCategory: parentId ? { _type: 'reference', _ref: parentId } : undefined
                })

                processDirectory(fullPath, categoryId)

            } else if (item.endsWith('.md') || item.endsWith('.mdx')) {
                // It's a page
                const fileContent = fs.readFileSync(fullPath, 'utf-8')
                const { data, content } = parseFrontmatter(fileContent)

                if (!parentId) {
                    console.warn(`âš ï¸  è·³è¿‡æ ¹ç›®å½•æ–‡ä»¶ ${item}ï¼ˆæ–‡æ¡£å¿…é¡»æ”¾åœ¨åˆ†ç±»ç›®å½•ä¸‹ï¼‰`)
                    return
                }

                const slug = data.slug || path.basename(item, path.extname(item))
                const pageId = generateId('page', slug)

                pages.push({
                    _id: pageId,
                    _type: 'docPage',
                    title: data.title || path.basename(item, path.extname(item)),
                    slug: { _type: 'slug', current: slug },
                    content: content,
                    category: { _type: 'reference', _ref: parentId },
                    order: data.order !== undefined ? parseInt(data.order) : index
                })
            }
        })
    }

    processDirectory(DOCS_DIR)

    // Output NDJSON
    const output = [
        ...categories.map(c => JSON.stringify(c)),
        ...pages.map(p => JSON.stringify(p))
    ].join('\n')

    const ioDir = path.join(process.cwd(), 'io')
    if (!fs.existsSync(ioDir)) {
        fs.mkdirSync(ioDir, { recursive: true })
    }
    const outputPath = path.join(ioDir, 'docs-import.ndjson')
    fs.writeFileSync(outputPath, output)

    console.log(`\nâœ… å¯¼å…¥æ–‡ä»¶å·²ç”Ÿæˆ: ${outputPath}`)
    console.log(`ğŸ“Š ç»Ÿè®¡: ${categories.length} ä¸ªåˆ†ç±»ï¼Œ${pages.length} ä¸ªæ–‡æ¡£`)
    console.log(`\næ‰§è¡Œä»¥ä¸‹å‘½ä»¤å¯¼å…¥åˆ° Sanityï¼š`)
    console.log(`   sanity dataset import ${outputPath} ${DATASET} --replace\n`)
}

main().catch(console.error)

